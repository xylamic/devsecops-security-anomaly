{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering and Generating Features\n",
    "This notebook is used to aggregate all the feature sets into a dataset that's ready for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:35:11.894792Z",
     "start_time": "2025-04-14T02:35:08.735303Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# import module from parent directory\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from library.analysis_utils import AnomalyV3Attrs\n",
    "\n",
    "pd.set_option('display.max_rows', 180)\n",
    "\n",
    "input_file = '../data/v3-ml-features-20250508.csv'\n",
    "target_file = '../data/v3-ml-complete-features-20250508.csv'\n",
    "\n",
    "contamination_value = 0.009\n",
    "\n",
    "# read in the dataset\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# convert 'day' column to a datetime\n",
    "df['day'] = pd.to_datetime(df['day'])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:35:21.025511Z",
     "start_time": "2025-04-14T02:35:21.002301Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter the columns I'm interested in\n",
    "df = df[AnomalyV3Attrs.BASE_FEATURES_TO_USE]\n",
    "df.head(5)\n",
    "\n",
    "    # excluding new_repo_git_clone, new_repo_git_push, new_repo_download, new_repo_workflow_run, active_read_repos_accessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:35:26.982712Z",
     "start_time": "2025-04-14T02:35:26.898137Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the earliest date in the dataset\n",
    "df['day'].min()\n",
    "\n",
    "# get the latest date in the dataset\n",
    "df['day'].max()\n",
    "\n",
    "# iterate from the earliest date to the latest date\n",
    "for day in pd.date_range(start=df['day'].min(), end=df['day'].max()):\n",
    "    print(f\"{day.strftime('%Y%m%d')}: {len(df[df['day'] == day])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:35:31.160259Z",
     "start_time": "2025-04-14T02:35:31.044779Z"
    }
   },
   "outputs": [],
   "source": [
    "# describe before after removal\n",
    "df_basefeatures: pd.DataFrame = df.copy()\n",
    "description_frame = df_basefeatures.describe(percentiles=[0.5, 0.75, 0.95, 0.99]).loc[['min', '50%', '75%', '95%', '99%', 'max']].transpose()\n",
    "display(description_frame)\n",
    "\n",
    "display(df_basefeatures.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create additional features\n",
    "\n",
    "There are additional features to be generated based on variations of individual user behavior over time, rather than on a single day compared to all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:35:32.659426Z",
     "start_time": "2025-04-14T02:35:32.652205Z"
    }
   },
   "outputs": [],
   "source": [
    "# these are the columns that will be EXCLUDED from generating features for deviations\n",
    "columns_to_zscore_exclude = set(AnomalyV3Attrs.FEATURES_TO_ZSCORE_EXCLUDE)\n",
    "\n",
    "# exclude the list of columns where the max value is 1 or less (significant on individual days, not deviation needed)\n",
    "bool_cols = description_frame.transpose().loc['max'] <= 1\n",
    "tiny_columns = bool_cols.index[bool_cols].tolist()\n",
    "for tiny_column in tiny_columns:\n",
    "    columns_to_zscore_exclude.add(tiny_column)\n",
    "\n",
    "print(f\"Exclude columns: {columns_to_zscore_exclude}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:35:33.610657Z",
     "start_time": "2025-04-14T02:35:33.450103Z"
    }
   },
   "outputs": [],
   "source": [
    "# get a copy of the dataframe without the excluded columns\n",
    "df_deviations = df_basefeatures.drop(columns=columns_to_zscore_exclude)\n",
    "\n",
    "# remove the 'day' column as it's not relevant for this calculation\n",
    "df_deviations = df_deviations.drop(columns=['day'])\n",
    "\n",
    "# get the average and standard deviation for each column for each actor\n",
    "df_deviations = df_deviations.groupby('actor').agg(['mean', 'std'])\n",
    "\n",
    "# for each column, replace any NaN in std with 0.0\n",
    "df_deviations = df_deviations.fillna(0.0)\n",
    "\n",
    "df_deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-04-14T02:35:34.727639Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "df_fulldayset = df_basefeatures.copy()\n",
    "\n",
    "# create a zscore for a given column/value in df_deviations\n",
    "def create_actor_zscore_column(column, row, df_deviations):\n",
    "    actor = row['actor']\n",
    "    mean = df_deviations.loc[actor, (column, 'mean')]\n",
    "    std = df_deviations.loc[actor, (column, 'std')]\n",
    "    value = row[column]\n",
    "\n",
    "    zscore = 0.0\n",
    "    if not math.isclose(std, 0, abs_tol=1e-9):\n",
    "        zscore = abs((value - mean) / std)\n",
    "    \n",
    "    if math.isnan(zscore):\n",
    "        print(f\"Nan values: actor {actor}, column {column}, value {value}, mean {mean}, std {std}\")\n",
    "\n",
    "    return zscore\n",
    "\n",
    "# for each column in df_deviations, create a new column in df_fulldayset with the zscore\n",
    "dev_columns = list(set([column[0] for column in df_deviations.columns]))\n",
    "for column in sorted(dev_columns):\n",
    "    print(f\"Processing column: {column}\")\n",
    "    df_fulldayset['zscore_' + column] = df_fulldayset.apply(\n",
    "        lambda row: create_actor_zscore_column(column, row, df_deviations), axis=1\n",
    "    )\n",
    "\n",
    "print(f\"Shape of df_fulldayset: {df_fulldayset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_fulldayset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_fullfeatures = df_fulldayset.copy()\n",
    "\n",
    "# describe after bot removal\n",
    "display(df_fullfeatures.describe(percentiles=[0.5, 0.75, 0.95, 0.99]).loc[['min', '50%', '75%', '95%', '99%', 'max']].transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do any data data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(\"Check for any rows with NaN values...\")\n",
    "\n",
    "# view any rows with NaN values\n",
    "display(df_fullfeatures[df_fullfeatures.isnull().any(axis=1)].transpose())\n",
    "\n",
    "# remove any rows with NaN values\n",
    "df_fullfeatures7d = df_fullfeatures.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the complete feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "df_fullfeatures.to_csv(target_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
